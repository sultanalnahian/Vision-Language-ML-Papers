# Vision-Language-ML-Papers

## Representation Learning

[ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks](https://arxiv.org/abs/1908.02265), NeurIPS 2019 [[code]](https://github.com/jiasenlu/vilbert_beta)

## Vision Transformer
[CrossViT: Cross-Attention Multi-Scale Vision Transformer for ImageClassification](https://arxiv.org/pdf/2103.14899.pdf), [[code]](https://github.com/lucidrains/vit-pytorch)
[CrossViT: Cross-Attention Multi-Scale Vision Transformer for ImageClassification](https://arxiv.org/pdf/2103.14899.pdf), [[code]](https://github.com/lucidrains/vit-pytorch)


ANIMAGE ISWORTH16X16 WORDS:TRANSFORMERS FORIMAGERECOGNITION ATSCALE
